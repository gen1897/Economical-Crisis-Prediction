{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore warnings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JST_df = pd.read_excel(\"JSTdatasetR4.xlsx\", sheet_name = \"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precrisis indicator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crisis have to be predicted before they happen. If we focus on the years with crisis, model will fit the features when it's to late. In order to avoid this, is a good option to create a new target variable with positive value 2 years before a crisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_precrisis(df):\n",
    "    df[\"precrisis\"] = 0\n",
    "    \n",
    "    for i in range(1,df.shape[0]):\n",
    "        if (df.loc[i, \"crisisJST\"] == 1):\n",
    "            df.loc[(i-1), \"precrisis\"] = 1\n",
    "            df.loc[(i-2), \"precrisis\"] = 1\n",
    "    return df\n",
    "\n",
    "JST_df = add_precrisis(JST_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features used in the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain variables used in the model. This includes transformations and creation of new variables. Some variables are expressed as percentual growth since immediate value doesnt mean nothing, it's important to know how they change before a crisis. This way also scales a little bit the values between diferent countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_variables(df):\n",
    "    # Slope of the yield curve\n",
    "    df[\"slope\"] = df[\"ltrate\"] - df[\"stir\"]\n",
    "    \n",
    "    # Global credit\n",
    "    df[\"global_credit\"] = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        year_it = df.loc[(i), \"year\"] \n",
    "        df[\"global_credit\"][i] = (df[df[\"year\"] == year_it].tloans.sum() - df.loc[(i), \"tloans\"])/(df[df[\"year\"] == year_it].tloans.shape[0] - 1)\n",
    "    df[\"gr_global_credit\"] = df[\"global_credit\"].pct_change(periods = 2) / df[\"gdp\"]\n",
    "    \n",
    "    # Log CPI\n",
    "    df[\"log_cpi\"] = np.log(df[\"cpi\"])\n",
    "    df[\"gr_log_cpi\"] = df[\"log_cpi\"].pct_change(periods = 2)\n",
    "    \n",
    "    # CA/GDP\n",
    "    df[\"ca_gdp\"] = df[\"ca\"]/df[\"gdp\"]\n",
    "    df[\"gr_ca_gdp\"] = df[\"ca_gdp\"].pct_change(periods = 2)\n",
    "    \n",
    "    # Log RGDP\n",
    "    df[\"log_real_gdp\"] = np.log(df[\"rgdpmad\"])\n",
    "    df[\"gr_log_real_gdp\"] = df[\"log_real_gdp\"].pct_change(periods = 2)\n",
    "    \n",
    "    # Log money\n",
    "    df[\"log_money\"] = np.log(df[\"money\"])\n",
    "    df[\"gr_log_money\"] = df[\"log_money\"].pct_change(periods = 2)\n",
    "    \n",
    "    # Log Domestic Credit\n",
    "    df[\"log_credit\"] = np.log(df[\"tloans\"])\n",
    "    df[\"gr_log_credit\"] = df[\"log_credit\"].pct_change(periods = 2)\n",
    "    \n",
    "    # Inversion\n",
    "    df[\"gr_inv\"] = df[\"iy\"].pct_change(periods = 2)\n",
    "    \n",
    "    # Acumulated Variance\n",
    "    df[\"roll_credit\"] = df.tloans.rolling(window=2 ,center=False).std()\n",
    "    df[\"roll_money\"] = df.money.rolling(window=2 ,center=False).std()\n",
    "    df[\"roll_ltrate\"] = df.ltrate.rolling(window=2 ,center=False).std()\n",
    "    \n",
    "    df[\"gr_gdp\"] = df[\"gdp\"].pct_change(periods = 2)\n",
    "    \n",
    "    return df\n",
    "\n",
    "pre_df = define_variables(JST_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop Bias PostCrisis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior period from a crisis is a recuperation time where economies are not healthy. Since they don't follow it's normal cycle, is better to drop the 5 years after a crisis and the year of the crisis itself. With this it's easier to avoid the bias produced and avoid confusing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_crisis_bias(df):\n",
    "    df[\"drops\"] = 0\n",
    "    \n",
    "    for i in range(1,(df.shape[0])):\n",
    "        if (df.loc[i, \"crisisJST\"] == 1):\n",
    "            df.loc[i, \"drops\"] = 1\n",
    "            df.loc[(i+1), \"drops\"] = 1\n",
    "            df.loc[(i+2), \"drops\"] = 1\n",
    "            df.loc[(i+3), \"drops\"] = 1\n",
    "            df.loc[(i+4), \"drops\"] = 1\n",
    "            df.loc[(i+5), \"drops\"] = 1  \n",
    "            \n",
    "    df = df[df[\"drops\"] == 0]\n",
    "    df = df.drop([\"drops\"], axis=1)\n",
    "    return df\n",
    "\n",
    "pre_df = drop_crisis_bias(pre_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pre_df[[\"precrisis\",\"slope\",\"gr_global_credit\",\"gr_log_cpi\",\"ca_gdp\",\"gr_log_real_gdp\",\"gr_log_money\",\n",
    "            \"gr_log_credit\",\"gr_inv\",\"year\",\"country\",\"stir\",\"gr_ca_gdp\",\"roll_credit\",\"roll_money\",\n",
    "            \"roll_ltrate\",\"gr_gdp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete worst years**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Years of Great Depression and World Wars may be excluded from data since they are periods where economy doesnt follow a normal trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_years(df):\n",
    "    excluded_years = [1914,1915,1916,1917,1918,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945]\n",
    "    df = df[~df[\"year\"].isin(excluded_years)]\n",
    "    return df\n",
    "\n",
    "df = drop_years(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(np.inf, np.NaN)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simplification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify model to 6 nordic countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_country(df, paises):\n",
    "    df = df[df[\"country\"].isin(paises)]\n",
    "    return df\n",
    "df = select_country(df,[\"Norway\",\"Switzerland\",\"Finland\",\"Germany\",\"Denmark\",\"Netherlands\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify to modern years (Post WWII)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"year\"] > 1949]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementati√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score\n",
    "\n",
    "\n",
    "def clasificacion(classifier, X, y):\n",
    "    y_train_pred = cross_val_predict(classifier, X, y ,cv=5)\n",
    "    print(\"Matriz de confusion:\")\n",
    "    print(confusion_matrix(y, y_train_pred))\n",
    "    print(\"AUC score:\",roc_auc_score(y.values, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"slope\",\"gr_global_credit\",\"gr_log_cpi\",\"ca_gdp\",\"gr_log_real_gdp\",\"gr_log_money\",\n",
    "            \"gr_log_credit\",\"gr_inv\"]]\n",
    "\n",
    "y = df[\"precrisis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regresion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion:\n",
      "[[317  17]\n",
      " [ 15   1]]\n",
      "AUC score: 0.5058008982035929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42, penalty=None, loss=\"log\")\n",
    "\n",
    "clasificacion(sgd_clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion:\n",
      "[[334   0]\n",
      " [ 14   2]]\n",
      "AUC score: 0.5625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=1000)\n",
    "\n",
    "pred = clasificacion(rf_clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extremely randomised trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion:\n",
      "[[333   1]\n",
      " [ 16   0]]\n",
      "AUC score: 0.49850299401197606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc_clf = ExtraTreesClassifier(n_estimators=1000, random_state=22)\n",
    "\n",
    "clasificacion(etc_clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion:\n",
      "[[314  20]\n",
      " [ 14   2]]\n",
      "AUC score: 0.5325598802395209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_clf = MLPClassifier(max_iter=1000, solver=\"lbfgs\", random_state=42)\n",
    "\n",
    "clasificacion(mlp_clf,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extreme gradient boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion:\n",
      "[[332   2]\n",
      " [ 16   0]]\n",
      "AUC score: 0.49700598802395207\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(random_state=42,n_estimators = 1000, learning_rate=0.1,min_child_weight=5)\n",
    "\n",
    "clasificacion(xgb_clf, X ,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal hyperparameters GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'activation': 'identity', 'alpha': 1e-05, 'learning_rate': 'constant', 'random_state': 42, 'solver': 'adam'}\n",
      "Score: 0.7948778833107191\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"solver\":[\"lbfgs\",\"adam\"],\"learning_rate\":[\"constant\",\"invscaling\",\"adaptative\"],\n",
    "              \"random_state\":[42],\"activation\":[\"identity\",\"logistic\",\"tanh\",\"relu\"],\n",
    "             \"alpha\":[0.00001,0.0005,]}\n",
    "\n",
    "mlp_clf = MLPClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(mlp_clf, param_grid, scoring=\"roc_auc\", cv=5, return_train_score = True)\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "print(\"Best params:\",grid_search.best_params_)\n",
    "print(\"Score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'activation': 'identity', 'alpha': 1e-05, 'learning_rate': 'constant', 'random_state': 42, 'solver': 'adam'}\n",
      "Score: 0.7948778833107191\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\",grid_search.best_params_)\n",
    "print(\"Score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logitstic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'eta0': 1e-05, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 500, 'penalty': 'elasticnet'}\n",
      "Score: 0.8587290818634102\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"loss\":[\"hinge\",\"log\",\"squared_loss\",\"huber\",\"epsilon_insensitive\"],\n",
    "             \"penalty\":[\"l2\",\"l1\",\"elasticnet\"],\"max_iter\":[500,1000,1500],\n",
    "             \"learning_rate\":[\"optimal\",\"constant\",\"adaptive\",\"invscaling\"],\n",
    "             \"eta0\":[0.00001,0.0001,0.005,0.1]}\n",
    "\n",
    "clf = SGDClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring=\"roc_auc\", cv=5, return_train_score = True)\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "print(\"Best params:\",grid_search.best_params_)\n",
    "print(\"Score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'log2', 'n_estimators': 50, 'random_state': 42}\n",
      "Score: 0.8734678878335593\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\":[50,100,300,500,1000,1500],\"criterion\":[\"gini\",\"entropy\"],\n",
    "             \"max_features\":[\"auto\",\"sqrt\",\"log2\"],\"random_state\":[42],\n",
    "              \"class_weight\":[\"balanced\",\"balanced_subsample\",None]}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring=\"roc_auc\", cv=5, return_train_score = True)\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "print(\"Best params:\",grid_search.best_params_)\n",
    "print(\"Score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extremely randomised trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'class_weight': None, 'criterion': 'entropy', 'max_features': 'auto', 'n_estimators': 300, 'random_state': 42}\n",
      "Score: 0.8760119855269111\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\":[50,100,300,500,1000,1500],\"criterion\":[\"gini\",\"entropy\"],\n",
    "             \"max_features\":[\"auto\",\"sqrt\",\"log2\"],\"random_state\":[42],\n",
    "              \"class_weight\":[\"balanced\",\"balanced_subsample\",None]}\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring=\"roc_auc\", cv=5, return_train_score = True)\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "print(\"Best params:\",grid_search.best_params_)\n",
    "print(\"Score:\",grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'grow_policy': 'depthwise', 'predictor': 'cpu_predictor', 'random_state': 42, 'sampling_method': 'uniform', 'tree_method': 'approx'}\n",
      "Score: 0.8565355042966983\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"random_state\":[42],\"sampling_method\":[\"uniform\",\"gradient_based\"],\n",
    "             \"tree_method\":[\"auto\",\"exact\",\"approx\",\"hist\",\"gpu_hist\"],\n",
    "             \"grow_policy\":['depthwise', 'lossguide'],\n",
    "             \"predictor\":[\"auto\",\"cpu_predictor\",\"gpu_predictor\"]}\n",
    "\n",
    "clf = XGBClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring=\"roc_auc\", cv=5, return_train_score = True)\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "print(\"Best params:\",grid_search.best_params_)\n",
    "print(\"Score:\",grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
